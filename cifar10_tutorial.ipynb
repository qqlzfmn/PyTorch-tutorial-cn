{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练分类器\n",
    "\n",
    "你已经知道怎么定义神经网络、计算损失并更新网络权重了。\n",
    "\n",
    "现在你可能会想，\n",
    "\n",
    "## 那数据呢？\n",
    "\n",
    "通常来说，当你需要处理图像、文本、音频或视频数据的时候，你可以使用把数据加载到 numpy array 的标准 Python 包。\n",
    "然后你就可以把这个 array 转换为 `torch.*Tensor` 了。\n",
    "\n",
    "- 对于图像，像 Pillow 和 OpenCV 这样的包是可以的\n",
    "- 对于音频，像 scipy 和 librosa 这样的包是可以的\n",
    "- 对于文本，基于 Python 或 Cython 的，或者 NLTK 和 SpaCy 都是可以的\n",
    "\n",
    "我们针对视觉场景构建了一个名叫 `torchvision` 的包，它包含用于 Imagenet 、 CIFAR10 、 MNIST 等常见数据集的数据加载器，以及用于图像的数据转换器，即 `torchvision.datasets` 和 `torch.utils.data.DataLoader` 。\n",
    "\n",
    "这提供了非常大的便利并且避免了编写重复代码。\n",
    "\n",
    "在这篇教程中，我们将使用 CIFAR10 数据集。\n",
    "它包含以下种类：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、货车。 \n",
    "CIFAR-10 中的图片尺寸是 3 x 32 x 32 的，也就是说，是 32 x 32 像素大小， 3 个色彩通道的彩色图片。\n",
    "\n",
    "![cifar10](./img/cifar10.png)\n",
    "\n",
    "## 训练一个图像分类器\n",
    "\n",
    "我们将顺序进行如下步骤：\n",
    "\n",
    "1. 使用 `torchvision` 加载并标准化 CIFAR10 的训练数据集和测试数据集\n",
    "2. 定义一个卷积神经网络\n",
    "3. 定义一个损失函数\n",
    "4. 使用训练数据训练网络\n",
    "5. 使用测试数据测试网络\n",
    "\n",
    "### 1. 加载并标准化 CIFAR10\n",
    "\n",
    "使用 `torchvision` 可以非常轻松地加载 CIFAR10 。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchvision` 数据集的输出是范围在 [0, 1] 的 PILImage 图像。\n",
    "我们将它们转换为标准化到范围 [-1. 1] 的 Tensor 。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更有意思，我们先展示一些训练图像。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 显示一张图片的函数\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # 非标准化\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 获取一些随机训练图像\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 显示图像\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印 label\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义一个卷积神经网络\n",
    "从之前讲神经网络的那一节把写好的代码复制过来，然后把它修改成接收 3 通道图像（替换掉原来定义的接收 1 通道图像那部分）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 定义一个损失函数和优化器\n",
    "让我们使用分类交叉熵损失和带动量的SGD。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 训练网络\n",
    "\n",
    "从这里开始事情将变得有趣起来。\n",
    "我们只需要循环遍历数据迭代器，然后将输入馈送给网络并进行优化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):  # 在数据集上循环迭代多次\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 得到输入\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 将参数梯度清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前项 + 后项 + 优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印统计结果\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # 每 2000 个小批次打印一次\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 使用测试数据测试网络\n",
    "\n",
    "我们已经使用训练数据集对网络进行了两次训练。\n",
    "但是我们需要检查一下网络究竟有没有学习到东西。\n",
    "\n",
    "我们将通过对比神经网络的预测输出种类标签（label）和图片的真实种类来检查这一点。\n",
    "如果预测正确，我们将样本添加到正确预测的列表中。\n",
    "\n",
    "好的，第一步。让我们显示一张测试集中的图像来熟悉测试集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 打印图像\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的，现在让我们看一看神经网络认为上面这些例子是什么：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出是 10 个种类的能量。\n",
    "一个种类的能量越高，神经网络越认为这幅图像属于这个种类。\n",
    "所以，让我们取得能量最高的 index ：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果看起来非常不错。\n",
    "\n",
    "让我们看一下神经网络在整个数据集上的表现怎么样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来结果比完全随机的情况好很多很多，因为完全随机的准确率应该是 10 % （从10个类别中随机选取一个类别）。\n",
    "网络应该是学到了一些东西的。\n",
    "\n",
    "看一下哪些是分类效果不错的类别，哪些是分类效果不是很好的类别：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步做什么呢？\n",
    "\n",
    "我们怎么在 GPU 上运行这个神经网络？\n",
    "\n",
    "## 在 GPU 上训练\n",
    "你可以像转移一个 Tensor 一样，将神经网络转移到 GPU 上。\n",
    "\n",
    "首先如果 CUDA 可用的话，将我们的设备定义为第一个可见的 cuda 设备：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 假设我们在一台 CUDA 设备上，这条语句就应该打印一个 CUDA 设备：\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一节剩下的内容假定 `device` 是 CUDA 设备。\n",
    "\n",
    "然后这些方法将递归遍历所有模块，并将它们的参数和缓存转换为 CUDA tensor 。\n",
    "\n",
    "```python\n",
    "    net.to(device)\n",
    "```\n",
    "\n",
    "记住，你每一步必须把输入和目标值（target）也送到 GPU：\n",
    "\n",
    "```python\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "```\n",
    "\n",
    "为什么我没有感觉到比使用 CPU 变快很多呢？因为你的网络太太太小了。\n",
    "\n",
    "**练习：**尝试增加网络宽度（第一个 `nn.Conv2d` 的第二个参数和第二个 `nn.Conv2d` 的第一个参数 - 它们需要是想用的数字），看看你能得到多大的加速。\n",
    "\n",
    "**达成目标：**\n",
    "\n",
    "- 较高水平地理解 PyTorch 的 Tensor 库和神经网络\n",
    "- 训练一个小神经网络来分类图像\n",
    "\n",
    "## 在多个 GPU 上训练\n",
    "如果你想看更多的使用 GPU 进行更快加速的内容，\n",
    "请查看[可选内容：数据并行](./data_parallel_tutorial.ipynb)\n",
    "\n",
    "## 下一步我可以看些什么？\n",
    "\n",
    "- [训练神经网络让它学会玩游戏](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)\n",
    "- [在 imagenet 上训练一个最先进的 ResNet](https://github.com/pytorch/examples/tree/master/imagenet)\n",
    "- [使用生成对抗网络训练一个人脸生成器](https://github.com/pytorch/examples/tree/master/dcgan)\n",
    "- [使用 LSTM 网络训练一个词级语言模型](https://github.com/pytorch/examples/tree/master/word_language_model)\n",
    "- [更多示例](https://github.com/pytorch/examples)\n",
    "- [更多教程](https://github.com/pytorch/tutorials)\n",
    "- [在论坛讨论 PyTorch](https://discuss.pytorch.org/)\n",
    "- [在 Slack 上与其他用户聊天](https://pytorch.slack.com/messages/beginner/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
